# -*- coding: utf-8 -*-
"""RMC wise_2 features_V3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11DgH7uE_oyWSv8BM-Q5PWhwX-T20r0e7
"""



# Commented out IPython magic to ensure Python compatibility.
!pip install xlsxwriter
!pip install --upgrade openpyxl
!pip install seaborn
!pip install plotly
!pip install statsmodels
!pip install imblearn
!pip install -U scikit-learn

import os
import datetime
from dateutil import parser
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib.dates as mdates
from tqdm.auto import tqdm
from collections import Counter
from datetime import datetime
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
import xlsxwriter
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import pearsonr
from collections import Counter

from matplotlib import pyplot as plt
import plotly.express as px
from statsmodels.distributions.empirical_distribution import ECDF
import seaborn as sns



pd.options.mode.chained_assignment = None
seed =10000
# %matplotlib inline
plt.style.use('fivethirtyeight')
plt.rcParams['figure.facecolor'] = 'white'
plt.style.use('Solarize_Light2')

color_map = ['#f58231','#000075','#3cb44b','#9A6324','#808000',
             '#000000','#e6194B','#800000','#42d4f4','#f032e6',
             '#a9a9a9','#dcbeff','#ffd8b1','#fabed4',"#a9a9a9",
             "#2792a5","#aec5c5","#bcbaa0","#b36200","#034710","#b0312d"]


#from google.colab import drive
#drive.mount('/content/drive/',force_remount=True)


#project_path = os.getcwd() + "/drive/MyDrive/Colab Notebooks/ONR_Basu_Roy/Aniruddha_Code/"
#print (project_path)

#project_path = os.getcwd() + "/drive/MyDrive/"
#print (project_path)
#data_path = project_path + 'data_in/'

data2 = pd.read_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/With_2_new_feature.csv', header=0)

data2.head()

data = data2[pd.DatetimeIndex(data2['ACTUAL_START_AVAIL']).year >= 2013]
data = data.sort_values(by='ACTUAL_START_AVAIL')
data = data[data["RCC_STATUS"] == "SETTLED"]
data["New_Delay_Threshold"] = data["PLANNED_AVAIL_DURATION"]*0.1

print(data["New_Delay_Threshold"].unique())

#data["target_label"] = [1 if x >7 else 0 for x in data["DELAY"]] ## >7 --> 1 else 0
data["target_label"] = 0
for ind in data.index:
     
  if data["DELAY"][ind] > data["New_Delay_Threshold"][ind]:
    data["target_label"][ind] = 1
  else:
    data["target_label"][ind] = 0

print(data['ACTUAL_START_AVAIL'])
print(data["target_label"])

data.columns

min_perc = int(data["Creation_%"].min())
max_perc = int(data["Settled_%"].max()+1)
def calculate_avg_active_rcc(df,group, filter, min_perc, max_perc):
  df_copy = df.copy()
  #print (Counter(df_copy[group]))

  df_copy["SSP#|RCC#"] = df_copy['SSP#'].astype(str) + " | " + df_copy['RCC#'].astype(str)
  df_copy["Creation_%"] = [int(x) for x in df_copy["Creation_%"]]
  df_copy = df_copy[df_copy["RCC_STATUS"] == 'SETTLED']
  df_copy = df_copy[df_copy["Settled_%"].isna() == False].reset_index(drop=True)
  df_copy["Settled_%"] = [int(x) for x in df_copy["Settled_%"]]

  all_group_data = pd.DataFrame(columns=[group,"target_label","Planned_Completion_%","Active_RCC"])

  for g in list(set(df_copy[group])):
    dg = df_copy[df_copy[group] == g]
    for t in list(set(dg["target_label"])):
      d = dg[dg["target_label"] == t]
      total_ssp_count = len(list(set(d["SSP#"]))) ##For the title
      total_rcc_count = len(list(set(d["SSP#|RCC#"]))) ##For the title
      total_unit_count = len(list(set(d["UNIT_ID"]))) ##For the title
      avg_delay = round(sum(list(set(d["DELAY"]))) / float(total_ssp_count),2)

      #all_xticks = [x for x in range(d["Creation_%"].min(),d["Settled_%"].max()+1)]
      all_xticks = [x for x in range(min_perc, max_perc)]
      all_xticks_df = pd.DataFrame(columns=["Planned_Completion_%"])
      all_xticks_df["Planned_Completion_%"] = all_xticks

      pivot_creat = d.groupby(["Creation_%"])["SSP#|RCC#"].agg("nunique").reset_index()
      pivot_creat = pivot_creat.rename(columns={"Creation_%" : "Planned_Completion_%"})
      pivot_creat_settl = all_xticks_df.merge(pivot_creat,how='left',on=["Planned_Completion_%"])
      pivot_creat_settl = pivot_creat_settl.fillna(0)
      pivot_creat_settl["SSP#|RCC#_created_cumsum"] = pivot_creat_settl["SSP#|RCC#"].cumsum()
      pivot_creat_settl = pivot_creat_settl[["Planned_Completion_%","SSP#|RCC#_created_cumsum"]]

      pivot_settl = d.groupby(["Settled_%"])["SSP#|RCC#"].agg("nunique").reset_index()
      pivot_settl = pivot_settl.rename(columns={"Settled_%" : "Planned_Completion_%"})
      pivot_creat_settl = pivot_creat_settl.merge(pivot_settl,how='left',on=["Planned_Completion_%"])
      pivot_creat_settl = pivot_creat_settl.fillna(0)
      pivot_creat_settl["SSP#|RCC#_settled_cumsum"] = pivot_creat_settl["SSP#|RCC#"].cumsum()

      pivot_creat_settl = pivot_creat_settl[["Planned_Completion_%","SSP#|RCC#_created_cumsum","SSP#|RCC#_settled_cumsum"]]
      pivot_creat_settl["Active_RCC"] = pivot_creat_settl["SSP#|RCC#_created_cumsum"] - pivot_creat_settl["SSP#|RCC#_settled_cumsum"]
      pivot_creat_settl["Active_RCC"] = [round(x/float(total_ssp_count),2) for x in pivot_creat_settl["Active_RCC"]]

      pivot_creat_settl[group] = [g] * len(pivot_creat_settl.index)
      pivot_creat_settl["target_label"] = [t] * len(pivot_creat_settl.index)
      pivot_creat_settl = pivot_creat_settl[[group,"target_label","Planned_Completion_%","Active_RCC"]]
      #print (g,"-->",pivot_creat_settl.shape)
      all_group_data = all_group_data.append(pivot_creat_settl)
  #print (all_group_data.shape)
  ##
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] >= 0)].reset_index(drop=True)
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] < 101)].reset_index(drop=True)
  #print (all_group_data["Planned_Completion_%"].min(),all_group_data["Planned_Completion_%"].max())
  #print (Counter(all_group_data["SSP#"]))
  ##

  all_group_data_T = all_group_data[["SSP#","Planned_Completion_%","Active_RCC"]].pivot(index=["SSP#"], columns=["Planned_Completion_%"],values=["Active_RCC"])
  all_group_data_T.columns = all_group_data_T.columns.droplevel()
  all_group_data_T = all_group_data_T.rename_axis(None,axis=1)
  all_group_data_T = all_group_data_T.reset_index()

  all_group_data_T = all_group_data_T[["SSP#"] + [x for x in range(0,101)]]
  if filter == 'All':
    all_group_data_T.columns = ["SSP#"] + ['Total_Active_RCC_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  else:
    all_group_data_T.columns = ["SSP#"] + [str(filter)+'_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  return all_group_data_T

#calculate_avg_active_rcc(data,"SSP#")

calculate_avg_active_rcc(data,"SSP#","All",min_perc, max_perc)

min_perc = int(data["Creation_%"].min())
max_perc = int(data["Settled_%"].max()+1)
def calculate_rcc_duration(df,group, filter, min_perc, max_perc):
  df_copy = df.copy()
  #print (Counter(df_copy[group]))

  df_copy["SSP#|RCC#"] = df_copy['SSP#'].astype(str) + " | " + df_copy['RCC#'].astype(str)
  df_copy["Creation_%"] = [int(x) for x in df_copy["Creation_%"]]
  df_copy = df_copy[df_copy["RCC_STATUS"] == 'SETTLED']
  df_copy = df_copy[df_copy["Settled_%"].isna() == False].reset_index(drop=True)
  df_copy["Settled_%"] = [int(x) for x in df_copy["Settled_%"]]

  all_group_data = pd.DataFrame(columns=[group,"target_label","Planned_Completion_%","RCC_DURATION"])

  all_group_data[all_group_data['RCC_DURATION'].astype(int) < 0] = 0

  for g in list(set(df_copy[group])):
    dg = df_copy[df_copy[group] == g]
    for t in list(set(dg["target_label"])):
      d = dg[dg["target_label"] == t]
      total_ssp_count = len(list(set(d["SSP#"]))) ##For the title
      total_rcc_count = len(list(set(d["SSP#|RCC#"]))) ##For the title
      total_unit_count = len(list(set(d["UNIT_ID"]))) ##For the title
      avg_delay = round(sum(list(set(d["DELAY"]))) / float(total_ssp_count),2)

      #all_xticks = [x for x in range(d["Creation_%"].min(),d["Settled_%"].max()+1)]
      all_xticks = [x for x in range(min_perc, max_perc)]
      all_xticks_df = pd.DataFrame(columns=["Planned_Completion_%"])
      all_xticks_df["Planned_Completion_%"] = all_xticks


      pivot_settl = d.groupby(["Settled_%"])["RCC_DURATION"].sum().reset_index()
      pivot_settl = pivot_settl.rename(columns={"Settled_%" : "Planned_Completion_%"})
      pivot_creat_settl = all_xticks_df.merge(pivot_settl,how='left',on=["Planned_Completion_%"])
      pivot_creat_settl = pivot_creat_settl.fillna(0)


      pivot_creat_settl = pivot_creat_settl[["Planned_Completion_%","RCC_DURATION"]]

      pivot_creat_settl[group] = [g] * len(pivot_creat_settl.index)
      pivot_creat_settl["target_label"] = [t] * len(pivot_creat_settl.index)
      pivot_creat_settl = pivot_creat_settl[[group,"target_label","Planned_Completion_%","RCC_DURATION"]]
      #print (g,"-->",pivot_creat_settl.shape)
      all_group_data = all_group_data.append(pivot_creat_settl)
  #print (all_group_data.shape)
  ##
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] >= 0)].reset_index(drop=True)
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] < 101)].reset_index(drop=True)
  #print (all_group_data["Planned_Completion_%"].min(),all_group_data["Planned_Completion_%"].max())
  #print (Counter(all_group_data["SSP#"]))
  ##

  all_group_data_T = all_group_data[["SSP#","Planned_Completion_%","RCC_DURATION"]].pivot(index=["SSP#"], columns=["Planned_Completion_%"],values=["RCC_DURATION"])
  all_group_data_T.columns = all_group_data_T.columns.droplevel()
  all_group_data_T = all_group_data_T.rename_axis(None,axis=1)
  all_group_data_T = all_group_data_T.reset_index()
  

  all_group_data_T = all_group_data_T[["SSP#"] + [x for x in range(0,101)]]
  if filter == 'All':
    all_group_data_T.columns = ["SSP#"] + ['RCC_duration_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  else:
    all_group_data_T.columns = ["SSP#"] + [str(filter)+'_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  
  
  return all_group_data_T

calculate_rcc_duration(data,"SSP#","All",min_perc, max_perc)

min_perc = int(data["Creation_%"].min())
max_perc = int(data["Settled_%"].max()+1)
def calculate_rcc_amount(df,group, filter, min_perc, max_perc):
  df_copy = df.copy()
  #print (Counter(df_copy[group]))

  df_copy["SSP#|RCC#"] = df_copy['SSP#'].astype(str) + " | " + df_copy['RCC#'].astype(str)
  df_copy["Creation_%"] = [int(x) for x in df_copy["Creation_%"]]
  df_copy = df_copy[df_copy["RCC_STATUS"] == 'SETTLED']
  df_copy = df_copy[df_copy["Settled_%"].isna() == False].reset_index(drop=True)
  df_copy["Settled_%"] = [int(x) for x in df_copy["Settled_%"]]

  all_group_data = pd.DataFrame(columns=[group,"target_label","Planned_Completion_%","RCC_SETTLED_AMOUNT"])

  for g in list(set(df_copy[group])):
    dg = df_copy[df_copy[group] == g]
    for t in list(set(dg["target_label"])):
      d = dg[dg["target_label"] == t]
      total_ssp_count = len(list(set(d["SSP#"]))) ##For the title
      total_rcc_count = len(list(set(d["SSP#|RCC#"]))) ##For the title
      total_unit_count = len(list(set(d["UNIT_ID"]))) ##For the title
      avg_delay = round(sum(list(set(d["DELAY"]))) / float(total_ssp_count),2)

      #all_xticks = [x for x in range(d["Creation_%"].min(),d["Settled_%"].max()+1)]
      all_xticks = [x for x in range(min_perc, max_perc)]
      all_xticks_df = pd.DataFrame(columns=["Planned_Completion_%"])
      all_xticks_df["Planned_Completion_%"] = all_xticks


      pivot_settl = d.groupby(["Settled_%"])["RCC_SETTLED_AMOUNT"].sum().reset_index()
      pivot_settl = pivot_settl.rename(columns={"Settled_%" : "Planned_Completion_%"})
      pivot_creat_settl = all_xticks_df.merge(pivot_settl,how='left',on=["Planned_Completion_%"])
      pivot_creat_settl = pivot_creat_settl.fillna(0)


      pivot_creat_settl = pivot_creat_settl[["Planned_Completion_%","RCC_SETTLED_AMOUNT"]]

      pivot_creat_settl[group] = [g] * len(pivot_creat_settl.index)
      pivot_creat_settl["target_label"] = [t] * len(pivot_creat_settl.index)
      pivot_creat_settl = pivot_creat_settl[[group,"target_label","Planned_Completion_%","RCC_SETTLED_AMOUNT"]]
      #print (g,"-->",pivot_creat_settl.shape)
      all_group_data = all_group_data.append(pivot_creat_settl)
  #print (all_group_data.shape)
  ##
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] >= 0)].reset_index(drop=True)
  #all_group_data = all_group_data[(all_group_data["Planned_Completion_%"] < 101)].reset_index(drop=True)
  #print (all_group_data["Planned_Completion_%"].min(),all_group_data["Planned_Completion_%"].max())
  #print (Counter(all_group_data["SSP#"]))
  ##

  all_group_data_T = all_group_data[["SSP#","Planned_Completion_%","RCC_SETTLED_AMOUNT"]].pivot(index=["SSP#"], columns=["Planned_Completion_%"],values=["RCC_SETTLED_AMOUNT"])
  all_group_data_T.columns = all_group_data_T.columns.droplevel()
  all_group_data_T = all_group_data_T.rename_axis(None,axis=1)
  all_group_data_T = all_group_data_T.reset_index()

  all_group_data_T = all_group_data_T[["SSP#"] + [x for x in range(0,101)]]
  if filter == 'All':
    all_group_data_T.columns = ["SSP#"] + ['RCC_Amount_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  else:
    all_group_data_T.columns = ["SSP#"] + [str(filter)+'_at_'+str(x)+'%' for x in all_group_data_T.columns if x != 'SSP#']
  return all_group_data_T

calculate_rcc_amount(data,"SSP#","All",min_perc, max_perc)

calculate_avg_active_rcc(data,"SSP#","New Growth-5",min_perc, max_perc)

# For RMC
def create_timeline_feature_ws_digits(data,min_perc, max_perc):
  all_classnames = list(set(data["RMC_NAME"]) - set(["NOT AVAILABLE"]))
  result = pd.DataFrame(columns=["RMC_NAME","SSP#"])

  for classnames in all_classnames:
    df = data.copy()
    df = df[df["RMC_NAME"] == classnames].reset_index(drop=True)
    df["rcc_type_ws_1_d"] = df["RCC_TYPE"].astype(str) + '-' + df["WS_FIRST_DIGIT"].astype(str)
    rcctyp_ws_1_d = list(set(df["rcc_type_ws_1_d"]))

    classnames_features = pd.DataFrame(columns=["RMC_NAME","SSP#"])
    classnames_features["SSP#"] = list(set(df["SSP#"]))
    classnames_features["RMC_NAME"] = [classnames] * len(classnames_features.index)
    
    total_active_df = calculate_avg_active_rcc(df,"SSP#","All", min_perc, max_perc)

    print(total_active_df)
    for rcc_ws in rcctyp_ws_1_d:
      filtered_df = df[df["rcc_type_ws_1_d"] == rcc_ws].reset_index(drop=True)
      #print (rcc_ws,"-->-->",filtered_df.shape)
      temp_active_df = calculate_avg_active_rcc(filtered_df,"SSP#",rcc_ws, min_perc, max_perc)
      temp_active_merged = temp_active_df.merge(total_active_df,on=["SSP#"]).fillna(0)

      for perc in range(0,101):
        temp_active_merged["Relative_Freq_"+str(rcc_ws)+"_"+str(perc)+"%"] = temp_active_merged[str(rcc_ws)+"_at_"+str(perc)+"%"] / temp_active_merged["Total_Active_RCC_at_"+str(perc)+"%"]
        temp_active_merged["Relative_Freq_"+str(rcc_ws)+"_"+str(perc)+"%"] = [round(x,4) for x in temp_active_merged["Relative_Freq_"+str(rcc_ws)+"_"+str(perc)+"%"]]
      temp_active_merged = temp_active_merged[["SSP#"] + [col for col in temp_active_merged.columns if "Relative_Freq_" in col]]
      temp_active_merged["RMC_NAME"] = [classnames] * len(temp_active_merged.index)      
      #print ([temp_active_merged[x].sum() for x in temp_active_merged.columns])
      classnames_features = classnames_features.merge(temp_active_merged,how='left',on=["RMC_NAME","SSP#"])

    result = pd.concat([result, classnames_features], axis=0, ignore_index=True)
    print (classnames,"-->",result.shape)

  #static_features = data[["SHIPYARD","SSP#","target_label","RMC_NAME","GROUP_NAME","HOMEPORT_NAME","RMC_NAME"]].drop_duplicates().reset_index(drop=True)
  #static_features = pd.get_dummies(data=static_features, columns=["GROUP_NAME","HOMEPORT_NAME","RMC_NAME", "RMC_NAME"])
  #display(static_features)
  #result = result.merge(static_features,how='left',on=["SHIPYARD","SSP#"]).fillna(0)
  #third_column = result.pop('target_label')
  #result.insert(2, 'target_label', third_column)
  return result


#res = create_timeline_feature_ws_digits(data,min_perc, max_perc)
#display(res)

# For RMC
def create_timeline_feature_ws_digits_duration(data,min_perc, max_perc):
  all_classnames = list(set(data["RMC_NAME"]) - set(["NOT AVAILABLE"]))
  result = pd.DataFrame(columns=["RMC_NAME","SSP#"])

  for classnames in all_classnames:
    df = data.copy()
    df = df[df["RMC_NAME"] == classnames].reset_index(drop=True)
    df["rcc_type_ws_1_d"] = df["RCC_TYPE"].astype(str) + '-' + df["WS_FIRST_DIGIT"].astype(str)
    rcctyp_ws_1_d = list(set(df["rcc_type_ws_1_d"]))

    classnames_features = pd.DataFrame(columns=["RMC_NAME","SSP#"])
    classnames_features["SSP#"] = list(set(df["SSP#"]))
    classnames_features["RMC_NAME"] = [classnames] * len(classnames_features.index)
    
    total_active_df = calculate_rcc_duration(data,"SSP#","All",min_perc, max_perc)

    print(total_active_df)
    for rcc_ws in rcctyp_ws_1_d:
      filtered_df = df[df["rcc_type_ws_1_d"] == rcc_ws].reset_index(drop=True)
      #print (rcc_ws,"-->-->",filtered_df.shape)
      temp_active_df = calculate_avg_active_rcc(filtered_df,"SSP#",rcc_ws, min_perc, max_perc)
      temp_active_merged = temp_active_df.merge(total_active_df,on=["SSP#"]).fillna(0)

      for perc in range(0,101):
        temp_active_merged["Relative_duration_"+str(rcc_ws)+"_"+str(perc)+"%"] = temp_active_merged[str(rcc_ws)+"_at_"+str(perc)+"%"] / temp_active_merged["RCC_duration_at_"+str(perc)+"%"]
        temp_active_merged["Relative_duration_"+str(rcc_ws)+"_"+str(perc)+"%"] = [round(x,4) for x in temp_active_merged["Relative_duration_"+str(rcc_ws)+"_"+str(perc)+"%"]]
      temp_active_merged = temp_active_merged[["SSP#"] + [col for col in temp_active_merged.columns if "Relative_duration_" in col]]
      temp_active_merged["RMC_NAME"] = [classnames] * len(temp_active_merged.index)      
      #print ([temp_active_merged[x].sum() for x in temp_active_merged.columns])
      classnames_features = classnames_features.merge(temp_active_merged,how='left',on=["RMC_NAME","SSP#"])

    result = pd.concat([result, classnames_features], axis=0, ignore_index=True)
    print (classnames,"-->",result.shape)

  #static_features = data[["SHIPYARD","SSP#","target_label","RMC_NAME","GROUP_NAME","HOMEPORT_NAME","RMC_NAME"]].drop_duplicates().reset_index(drop=True)
  #static_features = pd.get_dummies(data=static_features, columns=["GROUP_NAME","HOMEPORT_NAME","RMC_NAME", "RMC_NAME"])
  #display(static_features)
  #result = result.merge(static_features,how='left',on=["SHIPYARD","SSP#"]).fillna(0)
  #third_column = result.pop('target_label')
  #result.insert(2, 'target_label', third_column)
  result.replace([np.inf, -np.inf], 0, inplace=True)
  

  return result


#res_duration = create_timeline_feature_ws_digits_duration(data,min_perc, max_perc)
#display(res_duration)

# For RMC
def create_timeline_feature_ws_digits_amount(data,min_perc, max_perc):
  all_classnames = list(set(data["RMC_NAME"]) - set(["NOT AVAILABLE"]))
  result = pd.DataFrame(columns=["RMC_NAME","SSP#"])

  for classnames in all_classnames:
    df = data.copy()
    df = df[df["RMC_NAME"] == classnames].reset_index(drop=True)
    df["rcc_type_ws_1_d"] = df["RCC_TYPE"].astype(str) + '-' + df["WS_FIRST_DIGIT"].astype(str)
    rcctyp_ws_1_d = list(set(df["rcc_type_ws_1_d"]))

    classnames_features = pd.DataFrame(columns=["RMC_NAME","SSP#"])
    classnames_features["SSP#"] = list(set(df["SSP#"]))
    classnames_features["RMC_NAME"] = [classnames] * len(classnames_features.index)
    
    total_active_df = calculate_rcc_amount(data,"SSP#","All",min_perc, max_perc)

    print(total_active_df)
    for rcc_ws in rcctyp_ws_1_d:
      filtered_df = df[df["rcc_type_ws_1_d"] == rcc_ws].reset_index(drop=True)
      #print (rcc_ws,"-->-->",filtered_df.shape)
      temp_active_df = calculate_avg_active_rcc(filtered_df,"SSP#",rcc_ws, min_perc, max_perc)
      temp_active_merged = temp_active_df.merge(total_active_df,on=["SSP#"]).fillna(0)

      for perc in range(0,101):
        temp_active_merged["Relative_amount_"+str(rcc_ws)+"_"+str(perc)+"%"] = temp_active_merged[str(rcc_ws)+"_at_"+str(perc)+"%"] / temp_active_merged["RCC_Amount_at_"+str(perc)+"%"]
        temp_active_merged["Relative_amount_"+str(rcc_ws)+"_"+str(perc)+"%"] = [round(x,4) for x in temp_active_merged["Relative_amount_"+str(rcc_ws)+"_"+str(perc)+"%"]]
      temp_active_merged = temp_active_merged[["SSP#"] + [col for col in temp_active_merged.columns if "Relative_amount_" in col]]
      temp_active_merged["RMC_NAME"] = [classnames] * len(temp_active_merged.index)      
      #print ([temp_active_merged[x].sum() for x in temp_active_merged.columns])
      classnames_features = classnames_features.merge(temp_active_merged,how='left',on=["RMC_NAME","SSP#"])

    result = pd.concat([result, classnames_features], axis=0, ignore_index=True)
    print (classnames,"-->",result.shape)

  #static_features = data[["SHIPYARD","SSP#","target_label","RMC_NAME","GROUP_NAME","HOMEPORT_NAME","RMC_NAME"]].drop_duplicates().reset_index(drop=True)
  #static_features = pd.get_dummies(data=static_features, columns=["GROUP_NAME","HOMEPORT_NAME","RMC_NAME", "RMC_NAME"])
  #display(static_features)
  #result = result.merge(static_features,how='left',on=["SHIPYARD","SSP#"]).fillna(0)
  #third_column = result.pop('target_label')
  #result.insert(2, 'target_label', third_column)
  result.replace([np.inf, -np.inf], 0, inplace=True)
  return result


#res_amount = create_timeline_feature_ws_digits_amount(data,min_perc, max_perc)
#display(res_amount)

# For RMC
from sklearn.preprocessing import LabelEncoder

res = create_timeline_feature_ws_digits(data,min_perc, max_perc)
res_duration = create_timeline_feature_ws_digits_duration(data,min_perc, max_perc)
res_amount = create_timeline_feature_ws_digits_amount(data,min_perc, max_perc)

res_temp = res_duration.merge(res_amount,how='left',on=["SSP#"])
res = res.merge(res_temp,how='left',on=["SSP#"])
static_features = data[["RMC_NAME", "FULL_CLASS_NAME","SSP#","target_label","SHIPYARD","GROUP_NAME","HOMEPORT_NAME","Maintenance Frequency of WI","mean time to failure"]].drop_duplicates().reset_index(drop=True)

le = LabelEncoder()

objList = ["GROUP_NAME","HOMEPORT_NAME","FULL_CLASS_NAME", "SHIPYARD"]

for feat in objList:
  static_features[feat] = le.fit_transform(static_features[feat].astype(str))

print (static_features.info())

res = res.merge(static_features,how='left',on=["RMC_NAME","SSP#"]).fillna(0)

print(res)

res.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/RCCTYPE_WS1_features_active_rcc_RMC_2 features.csv',header=True)

data3 = pd.read_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/RCCTYPE_WS1_features_active_rcc_RMC_2 features.csv', header=0)
#data3 = pd.read_csv('RCCTYPE_WS1_features_active_rcc_RMC_2 features.csv', header=0)

data3 = data3.iloc[: , 1:]
data3.head()

#For RMC
!pip install imbalanced-learn
import random
import imblearn
from imblearn.over_sampling import RandomOverSampler
from collections import Counter
import sklearn.metrics as metrics
from sklearn.metrics import DistanceMetric

def create_train_test(df,classnames,test_size_perc):
  test_ssps = []
  if classnames == 'ALL':
    IP_df = df
  else:
    IP_df = df[df["RMC_NAME"] == classnames].reset_index(drop=True)
  delayed_ssps = list(set(IP_df[IP_df["target_label"] == 1]["SSP#"]))
  not_selayed_ssps = list(set(IP_df[IP_df["target_label"] == 0]["SSP#"]))

  print("number of delayed and not delayed ships")
  print (len(delayed_ssps),len(not_selayed_ssps))
  print ("sizes : {} --> {}".format(int(np.ceil(len(delayed_ssps) * test_size_perc)),int(np.ceil(len(not_selayed_ssps) * test_size_perc))))

  #test_ssps = test_ssps + random.sample(delayed_ssps, int(np.floor(len(delayed_ssps) * test_size_perc))) + random.sample(not_selayed_ssps, int(np.floor(len(delayed_ssps) * test_size_perc)))
  
  test_ssps = test_ssps + delayed_ssps[:int(np.ceil(len(delayed_ssps) * test_size_perc))] + not_selayed_ssps[:int(np.ceil(len(not_selayed_ssps) * test_size_perc))]
  train_ssps = list(set(IP_df["SSP#"]) - set(test_ssps))

  print("number of train and test ssp:")
  print (len(train_ssps),len(test_ssps))



  
  train_data = df[df['SSP#'].isin(train_ssps)].reset_index(drop=True)
  test_data = df[df['SSP#'].isin(test_ssps)].reset_index(drop=True)

  print("test data target label")
  print(test_data.target_label)

  print("train data target label")
  print(train_data.target_label)

  #increase train by 10 times
  
  train_inc = len(train_ssps)*10

  
  for i in range(train_inc - len(train_ssps)):
    train_data_sample = train_data.sample(random_state = 42)
    train_data = train_data.append(train_data_sample, ignore_index = True)
  
  

  print("length of train and test data:")
  print (len(train_data),len(test_data))



  print ("train data shape: ",train_data.shape)
  print ("test data shape: ",test_data.shape)
  return train_data,test_data
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
def prepare_features(df,max_perc):
  IP_df = df.copy()
  all_cols = ["GROUP_NAME","HOMEPORT_NAME","FULL_CLASS_NAME","SHIPYARD","Maintenance Frequency of WI","mean time to failure"]
  for perc in range(max_perc,max_perc+1):
    all_cols = all_cols + [cols for cols in IP_df.columns if "_"+str(perc)+"%" in cols]
  #print (all_cols)
  target = IP_df["target_label"]
  features = IP_df[all_cols]

  print(Counter(target))

  oversample = RandomOverSampler(sampling_strategy='minority', random_state = 42)
  features_over, target_over = oversample.fit_resample(features, target)

  print(Counter(target_over),features_over.columns)

  return features_over, target_over

def prepare_features2(df,max_perc):
  IP_df = df.copy()
  all_cols = ["GROUP_NAME","HOMEPORT_NAME","FULL_CLASS_NAME","SHIPYARD","Maintenance Frequency of WI","mean time to failure"]
  for perc in range(max_perc,max_perc+1):
    all_cols = all_cols + [cols for cols in IP_df.columns if "_"+str(perc)+"%" in cols]
  #print (all_cols)
  target = IP_df["target_label"]
  features = IP_df[all_cols]

  return features, target

#pip install imblearn

prepare_features(data3,5)

#Random Forest For classname
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
import plotly.graph_objects as go
from sklearn.model_selection import cross_val_score


def run_rf_wrapper(df,classnames,perc_list):

  '''
  acc = []
  auc = []
  X_train, X_test, y_train, y_test, X, y = prepare_features(df,perc_list)
  rfc_obj = RandomForestClassifier(class_weight='balanced')
  print ("===== Hyperparameter Tuning =====")
  n_estimators = [800,900,1000,1500]
  max_features = ['auto', 'sqrt']
  max_depth = [100,150,200,300]
  max_depth.append(None)

  '''
  train_acc = []
  test_acc = []
  all_train_data,all_test_data = create_train_test(df,classnames,0.20)
  w = {0:len(list(set(all_train_data[all_train_data['target_label'] == 1]["SSP#"]))),
       1:len(list(set(all_train_data[all_train_data['target_label'] == 0]["SSP#"])))}
  print (w)
  

  tree = RandomForestClassifier(max_depth=2, random_state=42,class_weight='balanced')

  memorization_train = {}
  memorization_test = {}
  #memorization = {}

  last_prev_df = pd.DataFrame()
  last_prev_df_test = pd.DataFrame()

  for p in perc_list:
    ind = perc_list.index(p)
    print("index:", ind)
    print ("------------------------------------------------------------------------------------------------------------")
    print ("RUNNING FOR {}%....".format(p))
    print ("------------------------------------------------------------------------------------------------------------")
    train_features,train_target = prepare_features(all_train_data,p)
    
    #print("train feature before:",train_features.head())

    test_features,test_target = prepare_features2(all_test_data,p)

    #print("test feature before:",test_features.head())
    
    current_columns_size = len(last_prev_df.columns)
    last_n_columns = 3
    if current_columns_size < last_n_columns:
        last_n_columns = current_columns_size
        
    if last_n_columns > 0:
        train_features = pd.concat([train_features, last_prev_df.iloc[:, -last_n_columns:]], axis=1)
        test_features = pd.concat([test_features, last_prev_df_test.iloc[:, -last_n_columns:]], axis=1)

    if ind-1 >= 0:
      prev_perc = perc_list[ind-1]
      prev_pred = memorization_train[prev_perc]

      prev_pred_test = memorization_test[prev_perc]

      #prev_pred_series = pd.Series(prev_pred) 
 
      #print("previous result train" ,prev_pred)
      #print("previous result test" ,prev_pred_test)

      prev_df = pd.DataFrame(prev_pred, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df)

      prev_df_test = pd.DataFrame(prev_pred_test, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df_test)    

      #train_target = train_target.append(prev_pred_series)

      #train_features = train_features.append(prev_df, ignore_index = True)
      train_features = pd.concat([train_features, prev_df], axis=1)

      test_features = pd.concat([test_features, prev_df_test], axis=1)

      print ("Test Features: ",test_features.shape,"Test Target: ",test_target.shape)

      print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)
        
      last_prev_df = pd.concat([last_prev_df, prev_df], axis=1)
      last_prev_df_test = pd.concat([last_prev_df_test, prev_df_test], axis=1)

      #print("train feature after:",train_features.head())

      #print("test feature after:",test_features.head())

    print("==================")
    print("train_features", train_features.columns)
    print("******************")
    tree.fit(train_features,train_target)
    #------------------------------------------------------------------------------------------------------------
    print ("-------------")
    # PREDICT


    test_pred = tree.predict(test_features)

    train_pred = tree.predict(train_features)
    print("train pred:", train_pred)

    memorization_train[p]= train_pred

    memorization_test[p]= test_pred

    #print("memorization train pred: ", memorization_train)
    #print("memorization test pred: ", memorization_test)

    print (metrics.confusion_matrix(test_target, test_pred))
    train_accuracy = metrics.accuracy_score(train_target, tree.predict(train_features))
    test_accuracy = metrics.accuracy_score(test_target, test_pred)
    
    train_acc.append(train_accuracy)
    test_acc.append(test_accuracy)

    #print("Tuned Decision Tree Parameters: {}".format(tree_cv.best_params_))
    #print("Best score is {}".format(tree_cv.best_score_))

  fig = go.Figure(data=go.Scatter(x = perc_list, y = [x * 100 for x in test_acc],line_color='red',name="Test"))
  fig.add_scatter(x = perc_list, y = [x * 100 for x in train_acc],line_color='blue',mode='lines',name="Train")
  fig.update_xaxes(title_text="Planned Completion %",ticksuffix="%")
  fig.update_yaxes(title_text="Accuracy",ticksuffix="%")
  fig.update_layout(title="Accuracy (Random Forest <b>{}</b>".format(classnames))

  fig.update_xaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.update_yaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.for_each_xaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.for_each_yaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.update_layout(legend=dict(title_font_family="Times New Roman",
                              font=dict(size= 20)))
  fig.update_layout(
    autosize=False,
    width=1000,
    height=1200)
  
  fig.show()

  return train_features, test_features, tree

train_f, test_f, tree = run_rf_wrapper(data3,"MARMC",[int(x) for x in range(5,36,5)])

list(train_f.columns)
print(len(train_f.columns))

train_f.shape

test_f.shape

for name, importance in zip(list(train_f.columns), tree.feature_importances_):
     
        print(name, "=", importance)

features = list(train_f.columns)
importances = tree.feature_importances_
#indices = np.argsort(importances)
indices = np.argsort(-importances)[:25]

plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

a= [features[i] for i in indices]
a.type

features_important_indices= pd.DataFrame()
#a= pd.DataFrame()
a= [features[i] for i in indices]
#features_important_indices= pd.concat(a, axis=1)
features_important_indices[1]=a
features_important_indices

#Random Forest For classname
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
import plotly.graph_objects as go
from sklearn.model_selection import cross_val_score


def run_rf_wrapper(df,classnames,perc_list):

  '''
  acc = []
  auc = []
  X_train, X_test, y_train, y_test, X, y = prepare_features(df,perc_list)
  rfc_obj = RandomForestClassifier(class_weight='balanced')
  print ("===== Hyperparameter Tuning =====")
  n_estimators = [800,900,1000,1500]
  max_features = ['auto', 'sqrt']
  max_depth = [100,150,200,300]
  max_depth.append(None)

  '''
  train_acc = []
  test_acc = []
  all_train_data,all_test_data = create_train_test(df,classnames,0.20)
  w = {0:len(list(set(all_train_data[all_train_data['target_label'] == 1]["SSP#"]))),
       1:len(list(set(all_train_data[all_train_data['target_label'] == 0]["SSP#"])))}
  print (w)
  

  tree = RandomForestClassifier(max_depth=2, random_state=42,class_weight='balanced')

  memorization_train = {}
  memorization_test = {}
  #memorization = {}

  last_prev_df = pd.DataFrame()
  last_prev_df_test = pd.DataFrame()
  features_important_indices = pd.DataFrame()
  

  for p in perc_list:
    ind = perc_list.index(p)
    print("index:", ind)
    print ("------------------------------------------------------------------------------------------------------------")
    print ("RUNNING FOR {}%....".format(p))
    print ("------------------------------------------------------------------------------------------------------------")
    train_features,train_target = prepare_features(all_train_data,p)
    
    #print("train feature before:",train_features.head())

    test_features,test_target = prepare_features2(all_test_data,p)

    #print("test feature before:",test_features.head())
    
    current_columns_size = len(last_prev_df.columns)
    last_n_columns = 3
    if current_columns_size < last_n_columns:
        last_n_columns = current_columns_size
        
    if last_n_columns > 0:
        train_features = pd.concat([train_features, last_prev_df.iloc[:, -last_n_columns:]], axis=1)
        test_features = pd.concat([test_features, last_prev_df_test.iloc[:, -last_n_columns:]], axis=1)

    if ind-1 >= 0:
      prev_perc = perc_list[ind-1]
      prev_pred = memorization_train[prev_perc]

      prev_pred_test = memorization_test[prev_perc]

      #prev_pred_series = pd.Series(prev_pred) 
 
      #print("previous result train" ,prev_pred)
      #print("previous result test" ,prev_pred_test)

      prev_df = pd.DataFrame(prev_pred, columns =["Prev_Result_at_"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df)

      prev_df_test = pd.DataFrame(prev_pred_test, columns =["Prev_Result_at_"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df_test)    

      #train_target = train_target.append(prev_pred_series)

      #train_features = train_features.append(prev_df, ignore_index = True)
      train_features = pd.concat([train_features, prev_df], axis=1)

      test_features = pd.concat([test_features, prev_df_test], axis=1)

      print ("Test Features: ",test_features.shape,"Test Target: ",test_target.shape)

      print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)
        
      last_prev_df = pd.concat([last_prev_df, prev_df], axis=1)
      last_prev_df_test = pd.concat([last_prev_df_test, prev_df_test], axis=1)

      #print("train feature after:",train_features.head())

      #print("test feature after:",test_features.head())

    
    
    
    print("==================")
    print("train_features", train_features.columns)
    print("******************")
    tree.fit(train_features,train_target)
    #------------------------------------------------------------------------------------------------------------
    print ("-------------")
    # PREDICT


    test_pred = tree.predict(test_features)

    train_pred = tree.predict(train_features)
    print("train pred:", train_pred)

    memorization_train[p]= train_pred

    memorization_test[p]= test_pred

    #print("memorization train pred: ", memorization_train)
    #print("memorization test pred: ", memorization_test)

    features = list(train_features.columns)
    importances = tree.feature_importances_
#indices = np.argsort(importances)
    indices = np.argsort(-importances)[:70]
    #features_important_indices= pd.concat([last_prev_df_test, prev_df_test], axis=1)
    features_important_indices[p]= [features[i] for i in indices]
    
    
    print (metrics.confusion_matrix(test_target, test_pred))
    train_accuracy = metrics.accuracy_score(train_target, tree.predict(train_features))
    test_accuracy = metrics.accuracy_score(test_target, test_pred)
    
    train_acc.append(train_accuracy)
    test_acc.append(test_accuracy)

    #print("Tuned Decision Tree Parameters: {}".format(tree_cv.best_params_))
    #print("Best score is {}".format(tree_cv.best_score_))

  fig = go.Figure(data=go.Scatter(x = perc_list, y = [x * 100 for x in test_acc],line_color='red',name="Test"))
  fig.add_scatter(x = perc_list, y = [x * 100 for x in train_acc],line_color='blue',mode='lines',name="Train")
  fig.update_xaxes(title_text="Planned Completion %",ticksuffix="%")
  fig.update_yaxes(title_text="Accuracy",ticksuffix="%")
  fig.update_layout(title="Accuracy (Random Forest <b>{}</b>".format(classnames))

  fig.update_xaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.update_yaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.for_each_xaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.for_each_yaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.update_layout(legend=dict(title_font_family="Times New Roman",
                              font=dict(size= 20)))
  fig.update_layout(
    autosize=False,
    width=1000,
    height=1200)
  
  fig.show()

  return train_features, test_features, tree,features_important_indices

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"MARMC",[int(x) for x in range(5,101,5)])

features_important_indices

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature.csv',header=True)

data_f = pd.read_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_V2.csv', header=0)
#data3 = pd.read_csv('RCCTYPE_WS1_features_active_rcc_RMC_2 features.csv', header=0)


data_f.head()









#import pandas as pd

# Example DataFrame
#df = pd.DataFrame.from_dict({'Name'  : ['May21', 'James', 'Adi22', 'Hello', 'Girl90'],
a=pd.DataFrame()                           
for column in features_important_indices:
    #if features_important_indices[column].str[:-1].isnumeric()==True:
        a[column]= features_important_indices[column].str[:-2].replace('[_\d%]', '')
#b= a.str.strip('d')
#str.replace('[$,]', '')
a
#print(b)

#!pip install shap
import shap
explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices= run_rf_wrapper(data3,"FDRMC-BAHRAIN",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_FDRMC-BAHRAIN.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"SWRMC",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_SWRMC.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"SERMC",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_SERMC.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"SRF-JRMC",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_SRF-JRMC.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree,features_important_indices = run_rf_wrapper(data3,"HRMC",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_HRMC.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"NWRMC",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_NWRMC.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree, features_important_indices = run_rf_wrapper(data3,"FDRMC-ROTA",[int(x) for x in range(5,101,5)])

features_important_indices.to_csv('/Users/md.rakibulhasan/Downloads/Pass Merge/important_feature_FDRMC-ROTA.csv',header=True)

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

# Logistic Regression
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
import plotly.graph_objects as go
from sklearn.model_selection import GridSearchCV
import scipy.stats as stats
from matplotlib import pyplot
import operator


def run_logistic_regr_wrapper(df,classnames,perc_list):
  
  train_acc = []
  test_acc = []
  all_train_data,all_test_data = create_train_test(df,classnames,0.2)
  #print(all_train_data.columns)
  #all_train_data,all_test_data = create_train_test2(df,shipyard)
  w = {0:len(list(set(all_train_data[all_train_data['target_label'] == 1]["SSP#"]))),
       1:len(list(set(all_train_data[all_train_data['target_label'] == 0]["SSP#"])))}
  print (w)

  param_grid = {'C': [  10, 100,1.0,0.1,0.01],
'solver': ['newton-cg','lbfgs','liblinear'],
'penalty': ['l2']}

  #best_model = LogisticRegression(C=10,penalty = 'l2', solver='newton-cg')

  best_model = LogisticRegression(C=0.01,penalty = 'l2', solver='liblinear', random_state = 42)
  #best_model = LogisticRegression(C=0.1,penalty = 'l2', solver='lbfgs')

  #grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)

  all_importants = pd.DataFrame(columns=["model_percentage", "feature_name", "importance_score"])

  memorization_train = {}
  memorization_test = {}
  last_prev_df = pd.DataFrame()
  last_prev_df_test = pd.DataFrame()
  for p in perc_list:
    ind = perc_list.index(p)
    print("index:", ind)
    feature_ranking= {}

    print ("------------------------------------------------------------------------------------------------------------")
    print ("RUNNING FOR {}%....".format(p))
    print ("------------------------------------------------------------------------------------------------------------")
    train_features,train_target = prepare_features(all_train_data,p)
    print(train_features.columns)
    print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)

    test_features,test_target = prepare_features2(all_test_data,p)

    #print("test feature before:",test_features.head())
    current_columns_size = len(last_prev_df.columns)
    last_n_columns = 3
    if current_columns_size < last_n_columns:
        last_n_columns = current_columns_size
        
    if last_n_columns > 0:
        train_features = pd.concat([train_features, last_prev_df.iloc[:, -last_n_columns:]], axis=1)
        test_features = pd.concat([test_features, last_prev_df_test.iloc[:, -last_n_columns:]], axis=1)

    if ind-1 >= 0:
      prev_perc = perc_list[ind-1]
      prev_pred = memorization_train[prev_perc]

      prev_pred_test = memorization_test[prev_perc]

      #prev_pred_series = pd.Series(prev_pred) 
 
      #print("previous result train" ,prev_pred)
      #print("previous result test" ,prev_pred_test)

      prev_df = pd.DataFrame(prev_pred, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df)

      prev_df_test = pd.DataFrame(prev_pred_test, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df_test)    

      #train_target = train_target.append(prev_pred_series)

      #train_features = train_features.append(prev_df, ignore_index = True)
      train_features = pd.concat([train_features, prev_df], axis=1)


      test_features = pd.concat([test_features, prev_df_test], axis=1)
      last_prev_df = pd.concat([last_prev_df, prev_df], axis=1)
      last_prev_df_test = pd.concat([last_prev_df_test, prev_df_test], axis=1)

      #print ("Test Features: ",test_features.shape,"Test Target: ",test_target.shape)

      #print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)

      #print("train feature after:",train_features.head())

      #print("test feature after:",test_features.head())

    best_model.fit(train_features,train_target)

    # get importance
    #importance = best_model.coef_[0]
    # summarize feature importance
    #for i,v in enumerate(importance):
      #print('Feature: %0d, Score: %.5f' % (i,v))
      #feature_ranking[train_features.columns[i]] = v
      #all_importants.loc[len(all_importants.index)] = [p,train_features.columns[i],v]


      
    #print("feature rankings:", feature_rankings)
    #actual name of the features
    
    #feature_rankings = dict( sorted(feature_ranking.items(), key=operator.itemgetter(1),reverse=True))
    #print("sorted feature rankings:", feature_rankings)

    #pyplot.bar([x for x in range(len(importance))], importance)
    #pyplot.show()


    #grid.fit(train_features,train_target)
    #print("grid best parameter:", grid.best_params_)
    #------------------------------------------------------------------------------------------------------------
    print ("-------------")
    # PREDICT
    
    test_pred = best_model.predict(test_features)

    train_pred = best_model.predict(train_features)

    #print("train pred:", train_pred)

    memorization_train[p]= train_pred

    memorization_test[p]= test_pred

    #test_pred = grid.predict(test_features)
    print (metrics.confusion_matrix(test_target, test_pred))
    train_accuracy = metrics.accuracy_score(train_target, best_model.predict(train_features))
    #train_accuracy = metrics.accuracy_score(train_target, grid.predict(train_features))
    test_accuracy = metrics.accuracy_score(test_target, test_pred)
    
    train_acc.append(train_accuracy)
    test_acc.append(test_accuracy)

  fig = go.Figure(data=go.Scatter(x = perc_list, y = [x * 100 for x in test_acc],line_color='red',name="Test"))
  fig.add_scatter(x = perc_list, y = [x * 100 for x in train_acc],line_color='blue',mode='lines',name="Train")
  fig.update_xaxes(title_text="Planned Completion %",ticksuffix="%")
  fig.update_yaxes(title_text="Accuracy",ticksuffix="%")
  #fig.update_layout(title="Accuracy (Logistic Regression (class_weight = balanced) <b>{}</b>".format(classnames))

  fig.update_xaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.update_yaxes(tickfont_size=20, ticks="outside", ticklen=10, tickwidth=5)
  fig.for_each_xaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.for_each_yaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.update_layout(legend=dict(title_font_family="Times New Roman",
                              font=dict(size= 20)))
  fig.update_layout(
    autosize=False,
    width=1000,
    height=1000)
  
  fig.show()


  #all_importants = all_importants.sort_values('importance_score', ascending=False)
  #return all_importants
  return train_features, test_features, tree

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'MARMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

for name, importance in zip(list(train_f.columns), tree.feature_importances_):
     print(name, "=", importance)

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'FDRMC-BAHRAIN',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'SWRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'SERMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'SRF-JRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'HRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'NWRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_logistic_regr_wrapper(data3,'FDRMC-ROTA',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

#Decision Tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
from sklearn import metrics
import plotly.graph_objects as go
from scipy.stats import randint

def run_decision_tree_wrapper(df,shipyard,perc_list):
  train_acc = []
  test_acc = []
  all_train_data,all_test_data = create_train_test(df,shipyard,0.20)
  w = {0:len(list(set(all_train_data[all_train_data['target_label'] == 1]["SSP#"]))),
       1:len(list(set(all_train_data[all_train_data['target_label'] == 0]["SSP#"])))}
  print (w)
  
  # Creating the hyperparameter grid 
  param_dist = {"max_depth": [3, None],
              "max_features": randint(1, 9),
              "min_samples_leaf": randint(1, 9),
              "criterion": ["gini", "entropy"]}
              
  #tree = DecisionTreeClassifier(criterion= 'entropy', max_depth= 3, max_features= 3, min_samples_leaf= 1)
  tree = DecisionTreeClassifier(criterion= 'gini', max_depth= 3, max_features= 5, min_samples_leaf= 1, random_state = 42)

  #tree_cv = RandomizedSearchCV(tree, param_dist, cv = 5)

  #grid_features,grid_target = prepare_features(all_train_data,5)
  


  memorization_train = {}
  memorization_test = {}
  last_prev_df = pd.DataFrame()
  last_prev_df_test = pd.DataFrame()

  for p in perc_list:
    ind = perc_list.index(p)
    print("index:", ind)

    print ("------------------------------------------------------------------------------------------------------------")
    print ("RUNNING FOR {}%....".format(p))
    print ("------------------------------------------------------------------------------------------------------------")
    train_features,train_target = prepare_features(all_train_data,p)
    print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)

    test_features,test_target = prepare_features2(all_test_data,p)

    #print("test feature before:",test_features.head())
    current_columns_size = len(last_prev_df.columns)
    last_n_columns = 5
    if current_columns_size < last_n_columns:
        last_n_columns = current_columns_size
        
    if last_n_columns > 0:
        train_features = pd.concat([train_features, last_prev_df.iloc[:, -last_n_columns:]], axis=1)
        test_features = pd.concat([test_features, last_prev_df_test.iloc[:, -last_n_columns:]], axis=1)
    if ind-1 >= 0:
      prev_perc = perc_list[ind-1]
      prev_pred = memorization_train[prev_perc]

      prev_pred_test = memorization_test[prev_perc]

      #prev_pred_series = pd.Series(prev_pred) 
 
      #print("previous result train" ,prev_pred)
      #print("previous result test" ,prev_pred_test)

      prev_df = pd.DataFrame(prev_pred, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df)

      prev_df_test = pd.DataFrame(prev_pred_test, columns =["Prev_Result_at"+str(prev_perc)+ "%"])
      #print("prev df:", prev_df_test)    

      #train_target = train_target.append(prev_pred_series)

      #train_features = train_features.append(prev_df, ignore_index = True)
      train_features = pd.concat([train_features, prev_df], axis=1)


      test_features = pd.concat([test_features, prev_df_test], axis=1)
      last_prev_df = pd.concat([last_prev_df, prev_df], axis=1)
      last_prev_df_test = pd.concat([last_prev_df_test, prev_df_test], axis=1)

      #print ("Test Features: ",test_features.shape,"Test Target: ",test_target.shape)

      #print ("Train Features: ",train_features.shape,"Train Trarget: ",train_target.shape)

      #print("train feature after:",train_features.head())

      #print("test feature after:",test_features.head())

    tree.fit(train_features,train_target)

    #------------------------------------------------------------------------------------------------------------
    print ("-------------")
    # PREDICT
    
    test_pred = tree.predict(test_features)
    train_pred = tree.predict(train_features)

    #print("train pred:", train_pred)

    memorization_train[p]= train_pred

    memorization_test[p]= test_pred

    print (metrics.confusion_matrix(test_target, test_pred))
    train_accuracy = metrics.accuracy_score(train_target, tree.predict(train_features))
    test_accuracy = metrics.accuracy_score(test_target, test_pred)
    
    train_acc.append(train_accuracy)
    test_acc.append(test_accuracy)

    #print(Tuned Decision Tree Parameters: {}".format(tree_cv.best_params_))
    #print("Best score is {}".format(tree_cv.best_score_))

  fig = go.Figure(data=go.Scatter(x = perc_list, y = [x * 100 for x in test_acc],line_color='red',name="Test"))
  fig.add_scatter(x = perc_list, y = [x * 100 for x in train_acc],line_color='blue',mode='lines',name="Train")
  fig.update_xaxes(title_text="Planned Completion %",ticksuffix="%")
  fig.update_yaxes(title_text="Accuracy",ticksuffix="%")
  fig.update_layout(title="Accuracy (Decision Tree (class_weight = balanced) <b>{}</b>".format(shipyard))

  fig.update_xaxes(tickfont_size=15, ticks="outside", ticklen=10, tickwidth=5)
  fig.update_yaxes(tickfont_size=15, ticks="outside", ticklen=10, tickwidth=5)
  fig.for_each_xaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.for_each_yaxis(lambda axis: axis.title.update(font=dict(size=24)))
  fig.update_layout(legend=dict(title_font_family="Times New Roman",
                              font=dict(size= 20)))
  fig.update_layout(
    autosize=False,
    width=1500,
    height=1000)
  
  fig.show()
  return train_features, test_features, tree

train_f, test_f, tree = run_decision_tree_wrapper(data3,'MARMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'FDRMC-BAHRAIN',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'SWRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'SERMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'SRF-JRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'HRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'NWRMC',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")

train_f, test_f, tree = run_decision_tree_wrapper(data3,'FDRMC-ROTA',[int(x) for x in range(5,101,5)])

explainer = shap.TreeExplainer(tree)
shap_values = explainer.shap_values(test_f)
shap.summary_plot(shap_values, test_f, plot_type="bar")











